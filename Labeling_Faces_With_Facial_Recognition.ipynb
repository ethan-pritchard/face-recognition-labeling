{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Labeling Faces With Facial Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObDWKOgJxDOXy3JTmLzdpv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT4RD0vzOUDf"
      },
      "source": [
        "# Labeling Faces with Facial Recongition\r\n",
        "\r\n",
        "This notebook utilizes the [facial recognition](https://github.com/ageitgey/face_recognition) library to recognize faces, encode the faces, and compare the encoded faces to known faces to find the closest match. The library itself handles the process of detecting faces and encoding them. This notebook builds a layer upon those two features to organize known users, attach multiple faces to a user, and label detected faces if we know the user.\r\n",
        "\r\n",
        "The technology created in this notebook is a great starting place to build real world facial recognition technology, such as a door lock that recognizes a database of users.\r\n",
        "\r\n",
        "Possible project ideas:\r\n",
        "* Door lock that queries a database of users to find matches and unlocks the door if all conditions are met (Example conditions: No condition, time frame condition for workplace or rentals)\r\n",
        "\r\n",
        "* Body cameras that queries a database of wanted individuals and notifies you if a wanted individual is found near you (Using wanted photos as user reference data) (Do you really want the police to use facial recognition though? Legality/ethics)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKIrJjfyHoja",
        "outputId": "a42f5902-a9aa-4fa0-f244-eec39add2402"
      },
      "source": [
        "!pip install https://github.com/ageitgey/face_recognition/archive/v1.2.2.tar.gz\r\n",
        "!pip install opencv-python\r\n",
        "!pip install "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/ageitgey/face_recognition/archive/v1.2.2.tar.gz\n",
            "\u001b[?25l  Downloading https://github.com/ageitgey/face_recognition/archive/v1.2.2.tar.gz\n",
            "\u001b[K     / 19.9MB 7.2MB/s\n",
            "\u001b[?25hCollecting face_recognition_models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 31kB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face-recognition==1.2.2) (7.1.2)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face-recognition==1.2.2) (19.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face-recognition==1.2.2) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face-recognition==1.2.2) (7.0.0)\n",
            "Building wheels for collected packages: face-recognition, face-recognition-models\n",
            "  Building wheel for face-recognition (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition: filename=face_recognition-1.2.2-py2.py3-none-any.whl size=15246 sha256=5d7c2a0fb1ede69f3252d402986bf4533a5989ab6d31d4f8d865d530c735e9db\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qszjljul/wheels/b1/ad/50/70c4119897208fd1bd524711e9fff3400b1621a769a42fe34f\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=d55e9a65ac7ae8b740f959e478901bf18d4f3b53053aaa3c348bf2326086177a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.2.2 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h5pvziwScaN"
      },
      "source": [
        "### Runtime Layer\r\n",
        "\r\n",
        "This is the layer that allows a runtime to create an array of **User** objects (all of your users) and compare them all to a possible face. If none of the users are matches, the method returns None. Otherwise, the user with the lowest distance to the possible face is the match."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v69om4epHaLU"
      },
      "source": [
        "import numpy as np\r\n",
        "import face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhGlfdAuHiEW"
      },
      "source": [
        "# A user will have an ID, a name (for labeling), and an array of face vectors\r\n",
        "class User:\r\n",
        "  def __init__(self, uuid, name, vectors=None):\r\n",
        "    self.uuid = uuid\r\n",
        "    self.name = name\r\n",
        "    self.vectors = vectors\r\n",
        "    if self.vectors is None or not isinstance(self.vectors, list): self.__init_vectors__()\r\n",
        "  \r\n",
        "  def __init_vectors__(self):\r\n",
        "    self.vectors = []\r\n",
        "  \r\n",
        "  def add_vector(self, v):\r\n",
        "    self.vectors.append(v)\r\n",
        "    return self\r\n",
        "  \r\n",
        "  def remove_vector(self, v):\r\n",
        "    self.vectors.remove(v)\r\n",
        "    return self\r\n",
        "  \r\n",
        "  def match(self, v):\r\n",
        "    return face_recognition.compare_faces(self.vectors, v)\r\n",
        "\r\n",
        "  def distance(self, v):\r\n",
        "    matches = self.match(v)\r\n",
        "    if len(matches) <= 0: return None\r\n",
        "    return np.min(face_recognition.face_distance(matches, v))\r\n",
        "\r\n",
        "  # Gets the name of the closest user, or returns None if no match is found\r\n",
        "  @staticmethod\r\n",
        "  def calculate_label(users, v):\r\n",
        "    # Calculate distance for all users\r\n",
        "    matches = []\r\n",
        "    for u in users:\r\n",
        "      u_dist = u.distance(v) # Only include users we have a match for\r\n",
        "      if u_dist is not None: matches.append((u, u_dist))\r\n",
        "    \r\n",
        "    # If we have no matches, we have no label\r\n",
        "    if len(matches) <= 0: return None\r\n",
        "\r\n",
        "    # Return the name of the closest face\r\n",
        "    closest = min(matches, key=lambda x: x[1])\r\n",
        "    return closest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD7wKiSZTvHE"
      },
      "source": [
        "### Example Implementation: Realtime Facial Detection & Labeling\r\n",
        "\r\n",
        "We can use OpenCV to run our webcam and periodically grab frames, scan the frames for faces, and label the faces if we find a match."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvkh6JrMYuh0"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoU1mJUOUgF_"
      },
      "source": [
        "# Method to continuously scan my webcam and detect users as they are found\r\n",
        "def webcam_detect(users=None, skip=2):\r\n",
        "  # Create webcam feed\r\n",
        "  video_capture = cv2.VideoCapture(0)\r\n",
        "\r\n",
        "  # Continuously loop over the webcam feed and try and label faces\r\n",
        "  fs = 0 # Frames skipped counter\r\n",
        "  while True:\r\n",
        "    # Get the RGB frame\r\n",
        "    ret, frame = video_capture.read()\r\n",
        "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\r\n",
        "    rgb_small_frame = small_frame[:,:,::-1]\r\n",
        "\r\n",
        "    # If we haven't reached skip count yet, we should skip this frame\r\n",
        "    if fs < skip:\r\n",
        "        fs += 1\r\n",
        "        continue\r\n",
        "    # We've skipped enough frames. Process this frame and reset counter\r\n",
        "    else: fs = 0\r\n",
        "\r\n",
        "    # Detect faces\r\n",
        "    face_locations = face_recognition.face_locations(rgb_small_frame)\r\n",
        "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\r\n",
        "\r\n",
        "    # Get names for faces\r\n",
        "    names = []\r\n",
        "    for v in face_encodings:\r\n",
        "        u = User.calculate_label(users, v)\r\n",
        "        if u is None: names.append('NOT A USER')\r\n",
        "        else: names.append(u[0].name)\r\n",
        "\r\n",
        "    # Label the detected faces with their name\r\n",
        "    for (top, right, bottom, left), name in zip(face_locations, names):\r\n",
        "      # Scale the images back to full\r\n",
        "      top *= 4\r\n",
        "      right *= 4\r\n",
        "      bottom *= 4\r\n",
        "      left *= 4\r\n",
        "\r\n",
        "      cv2.rectangle(frame, (left, top), (right, bottom), (0,0,255), 2)\r\n",
        "      cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0,0,255), cv2.FILLED)\r\n",
        "      cv2.putText(frame, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255,255,255), 1)\r\n",
        "    \r\n",
        "    # Show the resulting image\r\n",
        "    cv2.imshow('Video', frame)\r\n",
        "\r\n",
        "    # Exit condition\r\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'): break\r\n",
        "\r\n",
        "  # Destroy the CV2 instances\r\n",
        "  video_capture.release()\r\n",
        "  cv2.destroyAllWindows()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5TRg-Dier0y"
      },
      "source": [
        "# A simple helper method to load and encode the ith face in a file (Typically files only have 1 face)\r\n",
        "def encode_image(file, i=0):\r\n",
        "  return face_recognition.face_encodings(face_recognition.load_image_file(file))[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBxE_WC5arO0"
      },
      "source": [
        "# Create an array of users where each user has an ID, name, and a number of vectors to which we can recognize them\r\n",
        "users = [\r\n",
        "         User(1, 'Ethan').add_vector(encode_image('ethan.png')),\r\n",
        "         User(2, 'Ralph').add_vector(encode_image('ralph.png')),\r\n",
        "         User(3, 'Joe Biden').add_vector(encode_image('joe.png'))\r\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3dsiLQPnf-u"
      },
      "source": [
        "# Run the detect webcam (You need an OpenCV capable machine to run this. Google Colab will not work!)\r\n",
        "webcam_detect(users=users)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFgSw17pb74j"
      },
      "source": [
        "Results:\r\n",
        "\r\n",
        "![](https://i.imgur.com/oPqSE9e.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX9DJMpej5Qc"
      },
      "source": [
        "### Final Thoughts\r\n",
        "\r\n",
        "The majority of the stress comes from the iteration through all users. For a system to utilize facial recognition reliably, it must only process a small fraction of the frames captured by the sensor. This makes this library excellent for processing a set of pictures while being underwhelming for a video feed.\r\n",
        "\r\n",
        "Ultimately, the future of facial recognition relies on the ability to attach a face to existing user data. Services such as Facebook and Instagram are in excellent positions to make this connection due to the already massive amount of pre-labeled data. This notebook is a great starting point for a bigger project."
      ]
    }
  ]
}